// =============================================================================
// ğŸ¤– AI Services Integration - ì™„ì „ ìƒì„¸ ë²„ì „
// =============================================================================

export interface AIMessage {
  id: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
  metadata?: Record<string, any>;
}

export interface AIResponse {
  success: boolean;
  message?: string;
  tokensUsed?: number;
  processingTime?: number;
  error?: string;
  provider: 'openai' | 'anthropic' | 'gemini';
  model: string;
}

export type AIProvider = 'openai' | 'anthropic' | 'gemini';

// OpenAI ì„¤ì • ì¸í„°í˜ì´ìŠ¤
export interface OpenAIConfig {
  apiKey: string;
  model: string;
  maxTokens: number;
  temperature: number;
}

// Anthropic ì„¤ì • ì¸í„°í˜ì´ìŠ¤
export interface AnthropicConfig {
  apiKey: string;
  model: string;
  maxTokens: number;
  temperature: number;
}

// Gemini ì„¤ì • ì¸í„°í˜ì´ìŠ¤
export interface GeminiConfig {
  apiKey: string;
  model: string;
  maxTokens: number;
  temperature: number;
}

// =============================================================================
// OpenAI Service Implementation
// =============================================================================

export class OpenAIService {
  private config: OpenAIConfig;
  private client: any;

  constructor(config: OpenAIConfig) {
    this.config = config;
  }

  async initialize() {
    try {
      const { OpenAI } = await import('openai');
      this.client = new OpenAI({
        apiKey: this.config.apiKey,
      });
      return true;
    } catch (error) {
      console.error('OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      return false;
    }
  }

  async sendMessage(messages: AIMessage[]): Promise<AIResponse> {
    const startTime = Date.now();
    
    try {
      if (!this.client) {
        await this.initialize();
      }

      const response = await this.client.chat.completions.create({
        model: this.config.model,
        messages: messages.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        max_tokens: this.config.maxTokens,
        temperature: this.config.temperature,
      });

      const processingTime = Date.now() - startTime;

      return {
        success: true,
        message: response.choices[0]?.message?.content || '',
        tokensUsed: response.usage?.total_tokens || 0,
        processingTime,
        provider: 'openai',
        model: this.config.model
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        provider: 'openai',
        model: this.config.model,
        processingTime: Date.now() - startTime
      };
    }
  }
}

// =============================================================================
// Anthropic (Claude) Service Implementation
// =============================================================================

export class AnthropicService {
  private config: AnthropicConfig;
  private client: any;

  constructor(config: AnthropicConfig) {
    this.config = config;
  }

  async initialize() {
    try {
      const Anthropic = await import('@anthropic-ai/sdk');
      this.client = new Anthropic.default({
        apiKey: this.config.apiKey,
      });
      return true;
    } catch (error) {
      console.error('Anthropic ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      return false;
    }
  }

  async sendMessage(messages: AIMessage[]): Promise<AIResponse> {
    const startTime = Date.now();
    
    try {
      if (!this.client) {
        await this.initialize();
      }

      // ClaudeëŠ” system ë©”ì‹œì§€ë¥¼ ë³„ë„ë¡œ ì²˜ë¦¬
      const systemMessage = messages.find(m => m.role === 'system');
      const conversationMessages = messages.filter(m => m.role !== 'system');

      const response = await this.client.messages.create({
        model: this.config.model,
        max_tokens: this.config.maxTokens,
        temperature: this.config.temperature,
        system: systemMessage?.content || '',
        messages: conversationMessages.map(msg => ({
          role: msg.role,
          content: msg.content
        }))
      });

      const processingTime = Date.now() - startTime;

      return {
        success: true,
        message: response.content[0]?.text || '',
        tokensUsed: response.usage?.input_tokens + response.usage?.output_tokens || 0,
        processingTime,
        provider: 'anthropic',
        model: this.config.model
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        provider: 'anthropic',
        model: this.config.model,
        processingTime: Date.now() - startTime
      };
    }
  }
}

// =============================================================================
// Google Gemini Service Implementation
// =============================================================================

export class GeminiService {
  private config: GeminiConfig;
  private client: any;

  constructor(config: GeminiConfig) {
    this.config = config;
  }

  async initialize() {
    try {
      const { GoogleGenerativeAI } = await import('@google/generative-ai');
      this.client = new GoogleGenerativeAI(this.config.apiKey);
      return true;
    } catch (error) {
      console.error('Gemini ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      return false;
    }
  }

  async sendMessage(messages: AIMessage[]): Promise<AIResponse> {
    const startTime = Date.now();
    
    try {
      if (!this.client) {
        await this.initialize();
      }

      const model = this.client.getGenerativeModel({ 
        model: this.config.model,
        generationConfig: {
          maxOutputTokens: this.config.maxTokens,
          temperature: this.config.temperature,
        }
      });

      // GeminiëŠ” ëŒ€í™” ê¸°ë¡ì„ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
      const chat = model.startChat({
        history: messages.slice(0, -1).map(msg => ({
          role: msg.role === 'assistant' ? 'model' : 'user',
          parts: [{ text: msg.content }]
        }))
      });

      const lastMessage = messages[messages.length - 1];
      const response = await chat.sendMessage(lastMessage.content);
      const result = await response.response;

      const processingTime = Date.now() - startTime;

      return {
        success: true,
        message: result.text() || '',
        tokensUsed: result.usageMetadata?.totalTokenCount || 0,
        processingTime,
        provider: 'gemini',
        model: this.config.model
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        provider: 'gemini',
        model: this.config.model,
        processingTime: Date.now() - startTime
      };
    }
  }
}

// =============================================================================
// AI Service Manager - í†µí•© ê´€ë¦¬ì
// =============================================================================

export interface AIServiceConfig {
  openai: OpenAIConfig;
  anthropic: AnthropicConfig;
  gemini: GeminiConfig;
  defaultProvider: AIProvider;
}

export class AIServiceManager {
  private services: Map<AIProvider, OpenAIService | AnthropicService | GeminiService>;
  private config: AIServiceConfig;

  constructor(config: AIServiceConfig) {
    this.config = config;
    this.services = new Map();
    
    // ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    this.services.set('openai', new OpenAIService(config.openai));
    this.services.set('anthropic', new AnthropicService(config.anthropic));
    this.services.set('gemini', new GeminiService(config.gemini));
  }

  async initializeServices() {
    const results = await Promise.allSettled([
      this.services.get('openai')?.initialize(),
      this.services.get('anthropic')?.initialize(),
      this.services.get('gemini')?.initialize()
    ]);

    const successful = results.filter(r => r.status === 'fulfilled' && r.value === true).length;
    console.log(`AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”: ${successful}/3 ì„±ê³µ`);
    
    return successful > 0;
  }

  async sendMessage(
    messages: AIMessage[], 
    provider?: AIProvider
  ): Promise<AIResponse> {
    const selectedProvider = provider || this.config.defaultProvider;
    const service = this.services.get(selectedProvider);

    if (!service) {
      return {
        success: false,
        error: `ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì: ${selectedProvider}`,
        provider: selectedProvider,
        model: 'unknown',
        processingTime: 0
      };
    }

    return await service.sendMessage(messages);
  }

  async sendMessageWithFallback(messages: AIMessage[]): Promise<AIResponse> {
    const providers: AIProvider[] = ['openai', 'anthropic', 'gemini'];
    
    for (const provider of providers) {
      try {
        const response = await this.sendMessage(messages, provider);
        if (response.success) {
          return response;
        }
      } catch (error) {
        console.warn(`${provider} ì‹¤íŒ¨, ë‹¤ìŒ ì œê³µìë¡œ ì‹œë„...`);
        continue;
      }
    }

    return {
      success: false,
      error: 'ëª¨ë“  AI ì œê³µìê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤',
      provider: 'openai',
      model: 'unknown',
      processingTime: 0
    };
  }

  getAvailableProviders(): AIProvider[] {
    return Array.from(this.services.keys());
  }

  isProviderAvailable(provider: AIProvider): boolean {
    return this.services.has(provider);
  }

  // ê°œë³„ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  async checkServiceHealth(provider: AIProvider): Promise<boolean> {
    try {
      const testMessage = formatAIMessage('user', 'Hello');
      const response = await this.sendMessage([testMessage], provider);
      return response.success;
    } catch (error) {
      return false;
    }
  }

  // ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  async checkAllServicesHealth(): Promise<Record<AIProvider, boolean>> {
    const healthStatus: Record<AIProvider, boolean> = {
      openai: false,
      anthropic: false,
      gemini: false
    };

    const providers: AIProvider[] = ['openai', 'anthropic', 'gemini'];
    
    await Promise.all(
      providers.map(async (provider) => {
        healthStatus[provider] = await this.checkServiceHealth(provider);
      })
    );

    return healthStatus;
  }

  // í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
  private tokenUsageStats: Map<AIProvider, { count: number; tokens: number }> = new Map();

  trackTokenUsage(provider: AIProvider, tokens: number) {
    const current = this.tokenUsageStats.get(provider) || { count: 0, tokens: 0 };
    this.tokenUsageStats.set(provider, {
      count: current.count + 1,
      tokens: current.tokens + tokens
    });
  }

  getTokenUsageStats(): Map<AIProvider, { count: number; tokens: number }> {
    return new Map(this.tokenUsageStats);
  }

  resetTokenUsageStats() {
    this.tokenUsageStats.clear();
  }
}

// =============================================================================
// ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
// =============================================================================

export const createAIConfig = (): AIServiceConfig => ({
  openai: {
    apiKey: process.env.OPENAI_API_KEY || '',
    model: 'gpt-4',
    maxTokens: 2048,
    temperature: 0.7
  },
  anthropic: {
    apiKey: process.env.CLAUDE_API_KEY || '',
    model: 'claude-3-sonnet-20240229',
    maxTokens: 2048,
    temperature: 0.7
  },
  gemini: {
    apiKey: process.env.GEMINI_API_KEY || '',
    model: 'gemini-2.0-flash',
    maxTokens: 2048,
    temperature: 0.7
  },
  defaultProvider: 'openai'
});

export const formatAIMessage = (
  role: 'user' | 'assistant' | 'system',
  content: string,
  metadata?: Record<string, any>
): AIMessage => ({
  id: crypto.randomUUID(),
  role,
  content,
  timestamp: new Date(),
  metadata
});

export const validateAIResponse = (response: AIResponse): boolean => {
  return response.success && !!response.message && response.message.length > 0;
};

// WebAuthn ì—ëŸ¬ ë©”ì‹œì§€ ë³€í™˜
export const getWebAuthnErrorMessage = (error: string): string => {
  const errorMessages: Record<string, string> = {
    'NotAllowedError': 'ì‚¬ìš©ìê°€ ìš”ì²­ì„ ê±°ë¶€í–ˆê±°ë‚˜ íƒ€ì„ì•„ì›ƒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
    'SecurityError': 'ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.',
    'NetworkError': 'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
    'InvalidStateError': 'ì¸ì¦ê¸°ê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.',
    'ConstraintError': 'ìš”ì²­ëœ ì œì•½ ì¡°ê±´ì„ ë§Œì¡±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
    'NotSupportedError': 'ì´ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ì§€ì›ë˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.',
    'AbortError': 'ìš”ì²­ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.',
    'UnknownError': 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
  };

  return errorMessages[error] || errorMessages['UnknownError'];
};

// DID ìƒì„± í•¨ìˆ˜
export const generateDID = (method: string = 'web', identifier?: string): string => {
  const id = identifier || crypto.randomUUID();
  const rpId = process.env.WEBAUTHN_RP_ID || 'localhost';
  
  switch (method) {
    case 'web':
      return `did:web:${rpId}:users:${id}`;
    case 'key':
      return `did:key:${id}`;
    default:
      return `did:${method}:${id}`;
  }
};

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
let aiServiceManager: AIServiceManager | null = null;

export const getAIServiceManager = (): AIServiceManager => {
  if (!aiServiceManager) {
    const config = createAIConfig();
    aiServiceManager = new AIServiceManager(config);
  }
  return aiServiceManager;
};

// í¸ì˜ í•¨ìˆ˜ë“¤
export const sendAIMessage = async (
  content: string,
  provider?: AIProvider,
  conversationHistory: AIMessage[] = []
): Promise<AIResponse> => {
  const manager = getAIServiceManager();
  const userMessage = formatAIMessage('user', content);
  const messages = [...conversationHistory, userMessage];
  
  return await manager.sendMessage(messages, provider);
};

export const sendAIMessageWithFallback = async (
  content: string,
  conversationHistory: AIMessage[] = []
): Promise<AIResponse> => {
  const manager = getAIServiceManager();
  const userMessage = formatAIMessage('user', content);
  const messages = [...conversationHistory, userMessage];
  
  return await manager.sendMessageWithFallback(messages);
};

// ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
export class ConversationContext {
  private messages: AIMessage[] = [];
  private maxContextLength: number = 10;

  addMessage(message: AIMessage) {
    this.messages.push(message);
    
    // ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
    if (this.messages.length > this.maxContextLength) {
      this.messages = this.messages.slice(-this.maxContextLength);
    }
  }

  getMessages(): AIMessage[] {
    return [...this.messages];
  }

  clearContext() {
    this.messages = [];
  }

  setMaxContextLength(length: number) {
    this.maxContextLength = length;
    if (this.messages.length > length) {
      this.messages = this.messages.slice(-length);
    }
  }

  getTokenCount(): number {
    // ê°„ë‹¨í•œ í† í° ì¶”ì • (ì‹¤ì œë¡œëŠ” ë” ì •í™•í•œ í† í° ê³„ì‚°ê¸° ì‚¬ìš©)
    return this.messages.reduce((total, msg) => {
      return total + Math.ceil(msg.content.length / 4);
    }, 0);
  }
}

// AI ì‘ë‹µ ìºì‹±
export class AIResponseCache {
  private cache: Map<string, { response: AIResponse; timestamp: number }> = new Map();
  private cacheDuration: number = 5 * 60 * 1000; // 5ë¶„

  private generateCacheKey(messages: AIMessage[], provider: AIProvider): string {
    const content = messages.map(m => `${m.role}:${m.content}`).join('|');
    return `${provider}:${btoa(content)}`;
  }

  get(messages: AIMessage[], provider: AIProvider): AIResponse | null {
    const key = this.generateCacheKey(messages, provider);
    const cached = this.cache.get(key);
    
    if (cached && Date.now() - cached.timestamp < this.cacheDuration) {
      return cached.response;
    }
    
    // ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
    if (cached) {
      this.cache.delete(key);
    }
    
    return null;
  }

  set(messages: AIMessage[], provider: AIProvider, response: AIResponse) {
    const key = this.generateCacheKey(messages, provider);
    this.cache.set(key, {
      response,
      timestamp: Date.now()
    });
  }

  clear() {
    this.cache.clear();
  }

  size(): number {
    return this.cache.size;
  }
}

// ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
export const aiResponseCache = new AIResponseCache();